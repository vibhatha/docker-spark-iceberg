{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11205cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/23 04:05:52 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.master(\"local\")\n",
    "    .appName(\"IcebergPySpark\")\n",
    "    .config(\"spark.jars\", \"/home/asus/Downloads/iceberg-spark-runtime-3.2_2.12-1.2.0.jar\")\n",
    "    .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\")\n",
    "    .config(\"spark.sql.catalog.demo\", \"org.apache.iceberg.spark.SparkCatalog\")\n",
    "    .config(\"spark.sql.catalog.demo.catalog-impl\", \"org.apache.iceberg.rest.RESTCatalog\")\n",
    "    .config(\"spark.sql.catalog.demo.uri\", \"http://rest:8181\")\n",
    "    .config(\"spark.sql.catalog.demo.warehouse\", \"s3a://warehouse/wh/\")\n",
    "    .config(\"spark.sql.catalog.demo.s3.endpoint\", \"http://minio:9000\")\n",
    "    .config(\"spark.sql.defaultCatalog\", \"demo\")\n",
    "    .config(\"spark.eventLog.enabled\", \"true\")\n",
    "    .config(\"spark.eventLog.dir\", \"/home/iceberg/spark-events\")\n",
    "    .config(\"spark.history.fs.logDirectory\", \"/home/iceberg/spark-events\")\n",
    "    .config(\"spark.sql.catalogImplementation\", \"/home/iceberg/spark-events\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "71f78940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'default'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.currentDatabase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "36d58a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Database(name='default', description='default database', locationUri='file:/home/iceberg/notebooks/spark-warehouse')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listDatabases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a544dd98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='iceberg_pyspark_example', database='default', description=None, tableType='MANAGED', isTemporary=False)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f7ddb905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyiceberg.catalog.rest.RestCatalog at 0x7fe08c1733d0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyiceberg.catalog import load_catalog\n",
    "from pyiceberg.expressions import GreaterThanOrEqual\n",
    "\n",
    "iceberg_catalog = load_catalog('default')\n",
    "iceberg_catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "49cd1aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nyc',)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iceberg_catalog.list_namespaces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2a4b43e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "iceberg_catalog.create_namespace(\"sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0e7b35e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nyc',), ('sample',)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iceberg_catalog.list_namespaces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4ecf9d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_taxi_table = catalog.load_table((\"nyc\", \"taxis\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0226fadf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://warehouse/nyc/taxis'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyc_taxi_table.location()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c2485be8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TableAlreadyExistsError",
     "evalue": "AlreadyExistsException: Table already exists: sample.bids",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pyiceberg/catalog/rest.py:366\u001b[0m, in \u001b[0;36mRestCatalog.create_table\u001b[0;34m(self, identifier, schema, location, partition_spec, sort_order, properties)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 366\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 409 Client Error: Conflict for url: http://rest:8181/v1/namespaces/sample/tables",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTableAlreadyExistsError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 30\u001b[0m\n\u001b[1;32m     26\u001b[0m sort_order \u001b[38;5;241m=\u001b[39m SortOrder(SortField(source_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, transform\u001b[38;5;241m=\u001b[39mIdentityTransform()))\n\u001b[1;32m     28\u001b[0m iceberg_catalog \u001b[38;5;241m=\u001b[39m load_catalog(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 30\u001b[0m \u001b[43miceberg_catalog\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43midentifier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msample.bids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ms3://warehouse/sample/mytable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpartition_spec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartition_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort_order\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pyiceberg/catalog/rest.py:368\u001b[0m, in \u001b[0;36mRestCatalog.create_table\u001b[0;34m(self, identifier, schema, location, partition_spec, sort_order, properties)\u001b[0m\n\u001b[1;32m    366\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m--> 368\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_non_200_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m409\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mTableAlreadyExistsError\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m table_response \u001b[38;5;241m=\u001b[39m TableResponse(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse\u001b[38;5;241m.\u001b[39mjson())\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Table(\n\u001b[1;32m    373\u001b[0m     identifier\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midentifier_to_tuple(identifier),\n\u001b[1;32m    374\u001b[0m     metadata_location\u001b[38;5;241m=\u001b[39mtable_response\u001b[38;5;241m.\u001b[39mmetadata_location,\n\u001b[1;32m    375\u001b[0m     metadata\u001b[38;5;241m=\u001b[39mtable_response\u001b[38;5;241m.\u001b[39mmetadata,\n\u001b[1;32m    376\u001b[0m     io\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_file_io({\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtable_response\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mproperties, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtable_response\u001b[38;5;241m.\u001b[39mconfig}),\n\u001b[1;32m    377\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pyiceberg/catalog/rest.py:340\u001b[0m, in \u001b[0;36mRestCatalog._handle_non_200_response\u001b[0;34m(self, exc, error_handler)\u001b[0m\n\u001b[1;32m    335\u001b[0m     errs \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(err[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmsg\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m err \u001b[38;5;129;01min\u001b[39;00m e\u001b[38;5;241m.\u001b[39merrors())\n\u001b[1;32m    336\u001b[0m     response \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    337\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRESTError \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Received unexpected JSON Payload: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, errors: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merrs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    338\u001b[0m     )\n\u001b[0;32m--> 340\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception(response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mTableAlreadyExistsError\u001b[0m: AlreadyExistsException: Table already exists: sample.bids"
     ]
    }
   ],
   "source": [
    "from pyiceberg.catalog import load_catalog\n",
    "from pyiceberg.schema import Schema\n",
    "from pyiceberg.types import TimestampType, DoubleType, StringType, NestedField\n",
    "\n",
    "schema = Schema(\n",
    "    NestedField(\n",
    "        field_id=1, name=\"id\", field_type=TimestampType(), required=False\n",
    "    ),\n",
    "    NestedField(field_id=2, name=\"bid\", field_type=DoubleType(), required=False),\n",
    "    NestedField(field_id=3, name=\"ask\", field_type=DoubleType(), required=False),\n",
    "    NestedField(field_id=4, name=\"symbol\", field_type=StringType(), required=False),\n",
    ")\n",
    "\n",
    "from pyiceberg.partitioning import PartitionSpec, PartitionField\n",
    "from pyiceberg.transforms import DayTransform\n",
    "\n",
    "partition_spec = PartitionSpec(\n",
    "    PartitionField(\n",
    "        source_id=1, field_id=1000, transform=DayTransform(), name=\"datetime_day\"\n",
    "    )\n",
    ")\n",
    "\n",
    "from pyiceberg.table.sorting import SortOrder, SortField\n",
    "from pyiceberg.transforms import IdentityTransform\n",
    "\n",
    "sort_order = SortOrder(SortField(source_id=4, transform=IdentityTransform()))\n",
    "\n",
    "iceberg_catalog = load_catalog(\"default\")\n",
    "\n",
    "iceberg_catalog.create_table(\n",
    "    identifier=\"sample.bids\",\n",
    "    location=\"s3://warehouse/sample/mytable\",\n",
    "    schema=schema,\n",
    "    partition_spec=partition_spec,\n",
    "    sort_order=sort_order,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f4585c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('default',), ('nyc',), ('sample',)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iceberg_catalog.list_namespaces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "edddbc53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sample', 'bids')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iceberg_catalog.list_tables('sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "138a292a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('default', 'sample', 'bids')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbl = iceberg_catalog.load_table('sample.bids')\n",
    "tbl.name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7b9da442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2020, 5, 17, 0, 0)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0cb4ee94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiceberg.schema import Schema\n",
    "from pyiceberg.types import TimestampType, DoubleType, StringType, NestedField\n",
    "\n",
    "iceberg_table_name = \"default.sample.bids\"\n",
    "#spark.catalog.createTable(iceberg_table_name, schema=schema)\n",
    "\n",
    "write_schema = [\"id\", \"bid\", \"ask\", \"symbol\"]\n",
    "\n",
    "\n",
    "df = spark.createDataFrame([(datetime.datetime(2020, 5, 17), 10.2, 10.3, \"gold\")], write_schema)\n",
    "df.write.option(\"format\", \"iceberg\").mode(\"overwrite\").saveAsTable(iceberg_table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f4fae764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>bid</th>\n",
       "      <th>ask</th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-05-17 00:00:00+00:00</td>\n",
       "      <td>10.2</td>\n",
       "      <td>10.3</td>\n",
       "      <td>gold</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id   bid   ask symbol\n",
       "0 2020-05-17 00:00:00+00:00  10.2  10.3   gold"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbl = iceberg_catalog.load_table('default.sample.bids')\n",
    "sc = tbl.scan()\n",
    "df = sc.to_arrow().to_pandas()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3d827e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = iceberg_catalog.load_table('nyc.taxis')\n",
    "sc = tbl.scan()\n",
    "df = sc.to_arrow().to_pandas()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a5033a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-04-01 00:00:18+00:00</td>\n",
       "      <td>2021-04-01 00:21:54+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>79</td>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "      <td>25.50</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>35.15</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-04-01 00:42:37+00:00</td>\n",
       "      <td>2021-04-01 00:46:23+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>75</td>\n",
       "      <td>236</td>\n",
       "      <td>2</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.80</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-04-01 00:57:56+00:00</td>\n",
       "      <td>2021-04-01 01:08:22+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>236</td>\n",
       "      <td>168</td>\n",
       "      <td>2</td>\n",
       "      <td>11.50</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-04-01 00:01:58+00:00</td>\n",
       "      <td>2021-04-01 00:54:27+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>47</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>44.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>45.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-04-01 00:24:55+00:00</td>\n",
       "      <td>2021-04-01 00:34:33+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>238</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2171182</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-04-30 23:39:00+00:00</td>\n",
       "      <td>2021-04-30 23:56:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>158</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>16.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>25.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2171183</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-04-30 23:20:32+00:00</td>\n",
       "      <td>2021-04-30 23:23:05+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>141</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2171184</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-04-30 23:33:00+00:00</td>\n",
       "      <td>2021-04-30 23:55:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>90</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>21.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>31.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2171185</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-04-30 23:31:38+00:00</td>\n",
       "      <td>2021-04-30 23:45:18+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>75</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>16.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20.63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2171186</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-04-30 23:05:21+00:00</td>\n",
       "      <td>2021-04-30 23:17:15+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>141</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>12.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>18.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2171187 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         VendorID      tpep_pickup_datetime     tpep_dropoff_datetime  \\\n",
       "0               1 2021-04-01 00:00:18+00:00 2021-04-01 00:21:54+00:00   \n",
       "1               1 2021-04-01 00:42:37+00:00 2021-04-01 00:46:23+00:00   \n",
       "2               1 2021-04-01 00:57:56+00:00 2021-04-01 01:08:22+00:00   \n",
       "3               1 2021-04-01 00:01:58+00:00 2021-04-01 00:54:27+00:00   \n",
       "4               2 2021-04-01 00:24:55+00:00 2021-04-01 00:34:33+00:00   \n",
       "...           ...                       ...                       ...   \n",
       "2171182         2 2021-04-30 23:39:00+00:00 2021-04-30 23:56:00+00:00   \n",
       "2171183         1 2021-04-30 23:20:32+00:00 2021-04-30 23:23:05+00:00   \n",
       "2171184         2 2021-04-30 23:33:00+00:00 2021-04-30 23:55:00+00:00   \n",
       "2171185         2 2021-04-30 23:31:38+00:00 2021-04-30 23:45:18+00:00   \n",
       "2171186         1 2021-04-30 23:05:21+00:00 2021-04-30 23:17:15+00:00   \n",
       "\n",
       "         passenger_count  trip_distance  RatecodeID store_and_fwd_flag  \\\n",
       "0                    1.0           8.40         1.0                  N   \n",
       "1                    1.0           0.90         1.0                  N   \n",
       "2                    1.0           3.40         1.0                  N   \n",
       "3                    1.0           0.00         1.0                  N   \n",
       "4                    1.0           1.96         1.0                  N   \n",
       "...                  ...            ...         ...                ...   \n",
       "2171182              NaN           4.17         NaN               None   \n",
       "2171183              NaN           0.90         NaN               None   \n",
       "2171184              NaN           6.20         NaN               None   \n",
       "2171185              NaN           3.71         NaN               None   \n",
       "2171186              NaN           3.50         NaN               None   \n",
       "\n",
       "         PULocationID  DOLocationID  payment_type  fare_amount  extra  \\\n",
       "0                  79           116             1        25.50    3.0   \n",
       "1                  75           236             2         5.00    3.0   \n",
       "2                 236           168             2        11.50    3.0   \n",
       "3                  47            61             1        44.20    0.0   \n",
       "4                 238           152             1         9.00    0.5   \n",
       "...               ...           ...           ...          ...    ...   \n",
       "2171182           158           142             0        16.91    0.0   \n",
       "2171183           141           229             0         4.50    0.0   \n",
       "2171184            90            75             0        21.86    0.0   \n",
       "2171185            75           116             0        16.63    0.0   \n",
       "2171186           141           114             0        12.50    0.5   \n",
       "\n",
       "         mta_tax  tip_amount  tolls_amount  improvement_surcharge  \\\n",
       "0            0.5        5.85           0.0                    0.3   \n",
       "1            0.5        0.00           0.0                    0.3   \n",
       "2            0.5        0.00           0.0                    0.3   \n",
       "3            0.5        0.00           0.0                    0.3   \n",
       "4            0.5        3.09           0.0                    0.3   \n",
       "...          ...         ...           ...                    ...   \n",
       "2171182      0.5        4.83           0.0                    0.3   \n",
       "2171183      0.5        1.56           0.0                    0.3   \n",
       "2171184      0.5        6.08           0.0                    0.3   \n",
       "2171185      0.5        3.20           0.0                    0.3   \n",
       "2171186      0.5        2.45           0.0                    0.3   \n",
       "\n",
       "         total_amount  congestion_surcharge  airport_fee  \n",
       "0               35.15                   2.5          0.0  \n",
       "1                8.80                   2.5          0.0  \n",
       "2               15.30                   2.5          0.0  \n",
       "3               45.00                   0.0          0.0  \n",
       "4               13.39                   0.0          0.0  \n",
       "...               ...                   ...          ...  \n",
       "2171182         25.04                   NaN          NaN  \n",
       "2171183          9.36                   NaN          NaN  \n",
       "2171184         31.24                   NaN          NaN  \n",
       "2171185         20.63                   NaN          NaN  \n",
       "2171186         18.75                   NaN          NaN  \n",
       "\n",
       "[2171187 rows x 19 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbl = iceberg_catalog.load_table('nyc.taxis')\n",
    "sc = tbl.scan()\n",
    "df = sc.to_arrow().to_pandas()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78a916f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c10481e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o139.saveAsTable.\n: org.apache.iceberg.exceptions.NoSuchTableException: Invalid table identifier: iceberg_pyspark_example\n\tat org.apache.iceberg.rest.RESTSessionCatalog.checkIdentifierIsValid(RESTSessionCatalog.java:866)\n\tat org.apache.iceberg.rest.RESTSessionCatalog.access$100(RESTSessionCatalog.java:88)\n\tat org.apache.iceberg.rest.RESTSessionCatalog$Builder.<init>(RESTSessionCatalog.java:544)\n\tat org.apache.iceberg.rest.RESTSessionCatalog$Builder.<init>(RESTSessionCatalog.java:534)\n\tat org.apache.iceberg.rest.RESTSessionCatalog.buildTable(RESTSessionCatalog.java:392)\n\tat org.apache.iceberg.catalog.BaseSessionCatalog$AsCatalog.buildTable(BaseSessionCatalog.java:84)\n\tat org.apache.iceberg.rest.RESTCatalog.buildTable(RESTCatalog.java:103)\n\tat org.apache.iceberg.CachingCatalog$CachingTableBuilder.<init>(CachingCatalog.java:219)\n\tat org.apache.iceberg.CachingCatalog$CachingTableBuilder.<init>(CachingCatalog.java:214)\n\tat org.apache.iceberg.CachingCatalog.buildTable(CachingCatalog.java:211)\n\tat org.apache.iceberg.spark.SparkCatalog.newBuilder(SparkCatalog.java:788)\n\tat org.apache.iceberg.spark.SparkCatalog.stageCreate(SparkCatalog.java:241)\n\tat org.apache.spark.sql.execution.datasources.v2.AtomicCreateTableAsSelectExec.run(WriteToDataSourceV2Exec.scala:130)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:109)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:169)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:95)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:584)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:176)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:584)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:560)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:116)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:860)\n\tat org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:636)\n\tat org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:566)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m df \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mcreateDataFrame([], schema)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# #write.option(\"format\", \"iceberg\").mode(\"overwrite\")\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaveAsTable\u001b[49m\u001b[43m(\u001b[49m\u001b[43miceberg_table_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/sql/readwriter.py:1041\u001b[0m, in \u001b[0;36mDataFrameWriter.saveAsTable\u001b[0;34m(self, name, format, mode, partitionBy, **options)\u001b[0m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1040\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mformat\u001b[39m)\n\u001b[0;32m-> 1041\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaveAsTable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/sql/utils.py:190\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    192\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m/opt/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o139.saveAsTable.\n: org.apache.iceberg.exceptions.NoSuchTableException: Invalid table identifier: iceberg_pyspark_example\n\tat org.apache.iceberg.rest.RESTSessionCatalog.checkIdentifierIsValid(RESTSessionCatalog.java:866)\n\tat org.apache.iceberg.rest.RESTSessionCatalog.access$100(RESTSessionCatalog.java:88)\n\tat org.apache.iceberg.rest.RESTSessionCatalog$Builder.<init>(RESTSessionCatalog.java:544)\n\tat org.apache.iceberg.rest.RESTSessionCatalog$Builder.<init>(RESTSessionCatalog.java:534)\n\tat org.apache.iceberg.rest.RESTSessionCatalog.buildTable(RESTSessionCatalog.java:392)\n\tat org.apache.iceberg.catalog.BaseSessionCatalog$AsCatalog.buildTable(BaseSessionCatalog.java:84)\n\tat org.apache.iceberg.rest.RESTCatalog.buildTable(RESTCatalog.java:103)\n\tat org.apache.iceberg.CachingCatalog$CachingTableBuilder.<init>(CachingCatalog.java:219)\n\tat org.apache.iceberg.CachingCatalog$CachingTableBuilder.<init>(CachingCatalog.java:214)\n\tat org.apache.iceberg.CachingCatalog.buildTable(CachingCatalog.java:211)\n\tat org.apache.iceberg.spark.SparkCatalog.newBuilder(SparkCatalog.java:788)\n\tat org.apache.iceberg.spark.SparkCatalog.stageCreate(SparkCatalog.java:241)\n\tat org.apache.spark.sql.execution.datasources.v2.AtomicCreateTableAsSelectExec.run(WriteToDataSourceV2Exec.scala:130)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:109)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:169)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:95)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:584)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:176)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:584)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:560)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:116)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:860)\n\tat org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:636)\n\tat org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:566)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b671486f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
